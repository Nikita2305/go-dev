# SQL базы данных

## Базовые принципы

### ACID и уровни изоляции

https://habr.com/ru/companies/postgrespro/articles/442804/

Это модель надёжности транзакций.

Целостность данных - удовлетворение ограничениям целостности.

Иногда корректность данных в БД хочется определить иным языком, шире чем ограничениями целостности. Такие данные назовём согласованными. Например согласованность может определяться: "перевод никогда не меняет общей суммы денег на счетах". Однако обеспечить это ограничениями целостности БД достаточно трудно. Поэтому это правило сохраняется благодаря логики приложения: перевод состоит из двух операций, где первая нарушает согласованность данных, а вторая восстанавливает её. Мы не хотим, чтобы при каких либо условиях первое выполнилось без второго, поэтому БД предоставляет механизм транзакции и гарантирует её атомарность, таким образом помогая обеспечить согласованность.

Ещё одна проблема которая возникает - нарушение согласованности из-за параллельного исполнения транзакций и влияния "вставки" нескольких инструкций между последовательными операциями одной из транзакции. К примеру - грязое чтение (видим то, чего в БД никогда не было) Поэтому БД обеспечивает изолированность этих транзакций: "эквивалентность" (с точки зрения итогового результата) одному из вариантов последовательного исполнения.

Последнее, но не менее важное, это надёжность. Она утверждает что все зафиксированные транзакции будут сохранены в БД даже при сбое сервера или отключения питания. Можем ли мы синхронно начать обновлять БД при нажатии .commit() в коде? Нет, ведь если в этом процессе оторвётся питание, то мы оставим несогласованные данные. Поэтому .commit() гарантирует сохранение на диск в WAL, а затем начинает происходить обновление БД. Сохранение в WAL всех операций, включая коммит, гарантирует, что независимо от обстоятельств, эти данные попадут на диск.

Вот и получается: ACID. Транзакция перемещает состояние БД между корректными состояниями (обеспечивая согласованность), при условиях атомарности и изолированно от других транзакций. Однако изоляция, как и весь параллелизм, дело не простое, поэтому рассмотрим уровни изоляции и аномалии (помехи), которые они решают.

- Lost update - апдейт одной транзакции сделал +100, второй +100, но был сделан только апдейт (неатомарность update +=, условно говоря). 
- Dirty read - update[1] select[2] rollback[1]
    - Эту проблему решает READ COMMITED в стандарте. Хотя лучше сказать "Do not read uncommited".
- Неповторяющееся чтение. Это достаточно важный уровень. Представим задачу - ваша задача обработать не более 10000 запросов в API. Обработайте 10001 и у вас закончатся раздаваемый ресурс, пользователям покажется ошибка, а инвесторы расстроятся. Вы храните счётчик в БД: {resource_id, count}.

```sql
BEGIN
SELECT count FROM resources WHERE resource_id=1
-- Логика приложения:
-- if count >= 10000: 
--      return
UPDATE resources SET count = count + 1 WHERE resource_id=1
COMMIT
```

Проблема - Если две транзакции придут и селектнут count и получат 9999, то ваши дела плохи (сделав select после апдейта мы бы получили 10001 в одной из транзакций - неповторяющееся чтение). Поэтому приходит REPEATABLE READ - он гарантирует, что в такой ситуации наша программа отработает корректно. 

- Фантомное чтение: по факту аналогично неповторяющемуся чтению, только проблема в том, что мы сделаем некоторый запрос на чтение по некоторому селектору и получим другое значение. Пример, метод getOrCreateResource(user_id):

```sql
SELECT COUNT(*) FROM resources WHERE user_id=${user_id}
-- Логика приложение
-- if count > 0
--      return
INSERT INTO resources(user_id, resources) VALUES (${user_id}, 0)
```

То есть здесь решается проблема вставки. Эту аномалию решает Serializable. Согласно стандарту он обязан решать эту и все остальные известные и неизвестные аномалии (коих больше чем 4 штуки). 

*Лирическое отступление: изначально предполагалось что механизм изоляции будет построен на механизме блокировок строк. Упрощая: READ UNCOMMITED блокирует обновляемую строку от обновлений (тот кто пришёл её обновить - ждёт пока мы обновим, чтобы тоже обновить). READ COMMITED - дополнительно блокирует обновляемую строку от чтений (тот кто пришёл её прочитать - ждёт пока мы не закоммитим). REPEATABLE READ - дополнительно блокирует прочитанную строку от обновлений (и заодно от чтений, чтобы избежать дедлоков). SERIALIZABLE реализует предикатные блокировки - блокирует создание записей попадающий в предикат который был считан.*

Однако это не было реализовано.

Тут стоит оговориться, что это всё описание стандарта. Давайте вернёмся к PostgreSQL.

От механизма блокировок ушли, а пришли мы к слепкам - каждая транзакция получает слепок данных и работает далее с ним. В таком мире dirty read невозможен. И это приятно. Поэтому и READ UNCOMMITED эквивалентен READ COMMITED, поэтому его мы не рассматриваем. Также REPEATABLE READ дополнительно решает проблему фантомного чтения (принимаем во внимание, что иногда может падать). А зачем же тогда нужен SERIALIZABLE?

РОВНО ДВА кейса.

1. Несогласованная запись 

Исполним конкурентно две транзакции (под REPEATABLE READ):

```sql
SELECT sum(amount) FROM accounts WHERE client = 'bob';
-- Логика приложения
-- if sum < 100
--      return
UPDATE accounts SET amount = amount - 100 WHERE id = '{random}' 
```

Если нам id - дают рефернсы на два разных аккаунта, то мы можем совершить несогласованную запись, которая нарушит суммарную положительность на счетах.

В нашем маленьком мирке блокировок, нам казалось что мы заблокируем от чтений все строки боба и всё будет круто. Но пора просыпаться, ты в мире слепков постгреса. Другая имплементация, другие аномалии.

2. Аномалия только читающей транзакции - ещё один.

В обоих случаях serializable транзакции упадут и мы сможем их ретрайнуть, избежав несогласованности. Этот уровень изоляции позволяет не беспокоиться об аномалиях, но даёт необходмость писать ретраи + руинит перфоманс.

**Интересное замечание**: если ты выбрал SERIALIZABLE для транзакции, то лучше на уровне приложения. Иначе SERIALIZABLE могут вести себя как REPEATABLE READ. Чуть позже, погрузившись в реализацию, увидим почему так.

### К имплементации

https://habr.com/ru/companies/postgrespro/articles/445820/
https://habr.com/ru/companies/postgrespro/articles/446652/

`docker run --name pg-mvcc-test -e POSTGRES_PASSWORD=postgres -e POSTGRES_USER=postgres -e POSTGRES_DB=testdb -v pgdata:/var/lib/postgresql/data -p 5432:5432 -d postgres:16`

Транзакции имеют номера - возрастающий счётчик (не вдаваясь в детали переполнения) XID.

Строки имеют несколько версий (хранимых). Определённая транзакция видит определённые версии строк. Если транзакция решает создать строку, то она создаёт её с xmin=XID. Если транзакция решает удалить строку (некоторую её версию), то она устанавливает этой версии строки xmax=XID. Если обновить - то значит старой версии приписать xmax=XID, создать новую с xmin=XID.

Вопрос остаётся в том, как транзакция понимает, какие версии строк ей видеть. В дело вступает снепшот, он помогает определить какие версии строк видеть - благодаря описанию вида {xmin: int, xmax: int, xip: list[int]}. Xmin - минимальный номер активной транзакции. Xmax - минимальный номер транзакции который мы не видим (и все после него). XIP - множество активных транзакций. 

Таким образом, снимку будут видны все завершённые транзакции, а значит все транзакции < XMIN, и дополнительно множество, описываемое выражением [XMIN, XMAX) / XIP.

Снапшоты создаются с помощью похода в PROC_ARRAY - в shared buffer хранилище всех активных транзакций.

Как снимки связаны с транзакциями? В случае REPEATABLE READ и выше снепшот делается в начале транзакции. В случае READ COMMITED снепшот делается перед каждым оператором.

Получается, некоторый момент транзакции можем считать, что строки с XMIN в этом множестве и XMAX=null - актуальные. Если вдруг так получится, что мы начали транзакцию REPEATABLE READ сделали снепшот, а затем кто-то обновил строку. Теперь мы хотим обновить ту же строку, однако видим что актуальная версия имеет XMIN=XID (или XMAX!=0 - типа строку удалили) не из нашего множества (то есть снапшот устарел).

- Мы смотрим, активна ли эта транзакция XID или завершилась. Для этого есть PROC_ARRAY - там хранятся активные транзакции (в shared_buffer)

- Если транзакция не завершилась, то в случае REPEATABLE_READ мы ждём её завершения и переходим к следующему шагу.

- Если транзакция завершилась, то важно с каким статусом. Вдруг она была ROLLBACK-ed. Для этого есть хранилище XACT - там хранятся флаги commited и aborted (туда запишутся значения при коммите). Вычитав XACT, мы сможем понять, с каким статусом завершилась та транзакция и сделать вывод о том, можем ли продолжать. Интересная подробность - мы запишем в флаг xmin_aborted и xmin_commited верные значения. Это нужно чтобы реже ходить в XACT. Из интересного в этом случае SELECT  может спровоцировать запись на диск (чтобы обновить метаинформацию версий строк).

Так вот если T1-транзакция не завершилась (и поставила блокировку), а мы в T2 хотим сделать апдейт, мы неактивно блокируемся, затем разблокируемся, идём в XACT, записываем рядом xmin_commited/xmin_aborted результат T1, и если aborted, то можем спокойно сделать свой апдейт (в старой версии написать XMIN, XMAX=XID_T2, создать новую с XMIN=XID_T2). А что будет с устаревшей версией строки с XMIN=XID_T1? Её почистит vacuum.

Практика:

```sql
CREATE TABLE mvcc_test (
    id SERIAL PRIMARY KEY,
    val TEXT
);
INSERT INTO mvcc_test (val) VALUES ('initial');
```

T1:
```sql
BEGIN ISOLATION LEVEL REPEATABLE READ;
SELECT xmin, xmax, * FROM mvcc_test;
```

T2:
```sql
BEGIN ISOLATION LEVEL REPEATABLE READ;
SELECT xmin, xmax, * FROM mvcc_test;
```

T1:
```sql
INSERT INTO mvcc_test(id, val) VALUES (2, 'xxx');
```

T2:
```sql
INSERT INTO mvcc_test(id, val) VALUES (2, 'xxx');
-- Блокируется
```

Дальше два варианта, первый:

T1:
```sql
COMMIT;
```

T2:
```sql
-- Разблокировались
ERROR: connot serialize access
ROLLBACK;
```

Второй:

T1:
```sql
ROLLBACK;
```

T2:
```sql
-- Разблокировались
COMMIT;
```

Диагностика: `SELECT * FROM pg_stat_activity;`

## Блокировки

Построчные / потабличные. Очевидно бьют по перфомансу. `SELECT ... FOR UPDATE;` - блокирует остальные транзакции на запись сюда. `LOCK TABLE accounts IN ACCESS EXCLUSIVE MODE;` - блокирует всю таблицу на запись и чтение (даунтайм).

Диагностика: `SELECT * FROM pg_locks;`

## Индексы

Диагностика: `SELECT * FROM pg_indexes;` / `pg_stat_user_indexes`

База:

`CREATE INDEX name ON table(column);`

Строит `B-tree / Hash / ...` структуру данных, которая при поиске по описанной колонке помогает быстрее находить нужные строчки.

`REINDEX INDEX name;` / `DROP INDEX name;`

Тут стоит отметить что подобные операции с индексом блокируют таблицы на чтение `ACCESS EXCLUSIVE`, поэтому стоит использовать `СONCURRENTLY` ключевое слово, однако создание не гарантируется в таком случае. Есть табличка `pg_stat_progress_create_index` для мониторинга создания индекса.

По умолчанию на `PRIMARY KEY` есть `B-Tree INDEX`, так что с ним ты имеешь дело каждый день в любом случае.

Дополнительная семантика:

1) Составные индексы - указать несколько колонок, искать в том же порядке. `WHERE email = ? AND name = ?`
2) Частичный индекс: `CREATE INDEX idx_active_users ON users(email) WHERE is_active = true;`
Чтобы не индексировать ненужные записи. 
3) Покрывающий индекс: `CREATE INDEX idx_users_email_cover ON users(email) INCLUDE (name);`
Чтобы была возможность выдать результат селекта по индексу (Index only scan).

Здесь же можно отметить `VACUUM` / `AUTOVACUUM` / `VACUUM FULL`. Если первые два просто удаляют устаревшии версии строк для дальнейшего переиспользования, но не дефрагментируют диск (не уменьшают использованное пространство), то последний делает это. Пусть и с полной блокировкой как `REINDEX`.

Примеры:

Только для `=`
`CREATE INDEX idx_hash_email ON users USING hash(email);`

По умолчанию btree - широкий спектр
`CREATE INDEX idx_btree_email ON users(email);`

## EXPLAIN / EXPLAIN ANALYZE

Чтобы валидировать использование тех или иных индексов в конкретном запросе, можно смотреть
`EXPLAIN {SQL QUERY}` - показывает план исполнения (который составил планировщик)
`EXPLAIN ANALYZE {SQL QUERY}` - показывает план и исполняет запрос (показывая метрики исполнения exeuctor-а)

Разберёмся с планами.

Фильтрация:
- Seq Scan
- Parallel Seq Scan
- Index Scan

Когда будет выбран какой? На самом деле это зависит от многих факторов. Базово если нет индекса то один из первых двух. Если есть индекс - то в зависимости от данных. Если их мало - seq-scan / parallel seq scan. Если под условие попадает много данных (все или почти все), то нет смысла задействовать индекс, ибо всё равно с диска загружать всё. Если данные фрагментированные на диске (в индексе рядом, в таблице не рядом), то скорее всего чтобы вычитать данные из таблицы придётся прочитать почти все страницы с диска и нет смысла использовать индекс. Для выбора используется статистика планировщика, она помогает выстраивать оптимальные планы.

Для выполнения count или sum будет выполнено полное сканирование таблицы, что наверное не очень.

Соединение:
- Hash JOIN - маленькая таблица загружается в оперативку в качествве хэштаблицы по ключу соединения.
- Merge JOIN - есть индексы по ключам соединения.
- Nested Loop - в прочих случаях (в т.ч. данных мало).

## Логгирование

Чтобы понять, какие запросы тормозят и их стоит проанализировать, можно выставить `log_statement = 'all'`, `log_duration = on`, `log_min_duration_statement = 1000ms` - будет логгировать в /logs. Они по идее ротируются, по крайней мере есть такой параметр.

Ещё есть инструмент pg_stat_statements, который будет складывать запросы в отдельную табличку. 

## 

## Хайлоад

Что можно поднастроить в Postgres чтобы ваша жизнь стала лучше.

1) Возможно не хватает `shared buffer`. Это место в RAM в котором хранятся часто используемые данные. Выдаётся до 50% RAM машины.

2) Возможно `work_mem` нужно поднять. Это место в RAM, в котором производятся Hash JOIN, Sort и вот это всё (выделяется на исполнение одного узла дерева плана). Иначе алгоритмы будут использовать диск, когда это не нужно (и у нас есть свободная память). Поднимать слишком сильно тоже не стоит, иначе OOM.

3) `effective_cache_size` - это estimate того, сколько RAM используется под файловый кэш.

4) `max_connections` - увеличить количество соединений. Аккуратно - каждое соединение отдельный процесс со своим потреблением RAM.

### Репликация

Есть `Streaming Replication` - отправка с мастера на ридонли реплики. По умолчанию асинхронно с WAL лога доезжают апдейт до реплик, но можно сделать и синхронно.

Есть и пабсаб.

### Шардирование

Ещё в рамках одного инстанса, если табличка большая, то можно сделать `Declarative parititoning` - разбить табличку по партициям-файлам, что уменьшает фрагментацию / индексы / и возможно даже контеншн.

Есть ещё `Foreign Data Wrapper` - возможность создавать таблицы на удалённых серверах. Условно большую табличку побить на несколько шардов и селектить из нужного.

В качестве оптимального варианта шардирования БД - можно воспользоваться `citusDB` или `cockroachDB`.

### Классификация OLTP vs OLAP

Online Transaction Processing vs Online Analytics Processing

В первом случае у нас много маленьких CRUD, во втором большие и сложные запросы.

Классические проблемы OLTP:
- Блокировки (много конкурентных апдейтов на одних строках)
    - Решение: вынос в другую БД (Redis) + асинхронная синхронизация
    - Решение: избегание лишних блокировок
    - Решение: неблокирующие обновления / удаления (по etag)
- Bloating (фрагментация из-за старых версий строк)
    - Скорее всего автовакуум не справляется, надо ему помочь воркерами 
    - Можно партиционировать, чтобы автоваккуму было проще
    - Если уже произошло VACUUM FULL / Reindex, но с даунтаймом
- Индексы:
    - проблема в том, что апдейты начинают влиять на кучу индексов, это долго
        - Убрать лишние индексы, посмотреть EXPLAIN
    - проблема в том, что перестаёт влезать в память
        - Частичные индексы (только по нужным записям)
        - Партиционирование

Чаще это write-heavy система
- WAL может грузить диск, ему можно помочь через компрессию или батчевание записей?
- Повысить disk tx bandwidth 

Классические проблемы OLTP:
- Тормозят запросы
    - увеличить RAM / CPU, work_mem
    - оптимизировать вытаскивание лишних колонок и строк (в join часто)
    - использовать предподсчёты (materialized view)
    - переехать в другую БД
    - можно партиционировать, если это поможет уменьшить селекты
- OOM
    - уменьшить work_mem
    - добавить пагинацию

Чаще это read-heavy система
- Read only реплика может помочь
- Индексы, конечно

### Запросы в БД тормозят, что делать?

1. Slowlog операции
- Если что можно настроить в рантайме
2. EXPLAIN (QUERY)
3. Проблема срочная? Можем добавить индекс CREATE INDEX CONCURRENTLY если он поможет и не загрузит update.
4. Смотрим на статистику инстанса
- Диск (bw)
- RAM (bw)
- CPU

4. work_mem, shared_buffers - мб поднять?
5. смотрим на фрагментацию таблиц и индексов
- если всё плохо то помогаем вакууму воркерами и планируем FULL VACUUM и возможно REINDEX
6. Оптимизировать запрос - убрать лишние *, оптимизировать индекс - частичный / покрывающий
7. партицируем таблицы?
8. добавляем read replicas? убиваем аналитиков?
9. выносим часть логики наружу? кэши / highload redis?

